{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81348276",
   "metadata": {},
   "source": [
    "# Credit Risk — XGBoost (Hosted DB Edition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4bb605",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, numpy as np, pandas as pd\n",
    "from pathlib import Path\n",
    "DATA = Path(\"data\"); MODEL = Path(\"model\")\n",
    "features = pd.read_csv(DATA/\"features_training.csv\", index_col=0)\n",
    "feature_cols = [\n",
    "    \"income_inflow_30d\",\"spend_outflow_30d\",\"pct_gambling_spend_90d\",\"merchant_diversity_90d\",\n",
    "    \"avg_debit_amt_30d\",\"num_big_txn_30d\",\"days_since_last_salary\",\"debit_credit_ratio_90d\",\n",
    "    \"late_fee_count_90d\",\"debit_txn_count_30d\",\"credit_txn_count_30d\",\"net_cash_flow_30d\",\"cash_withdrawal_90d\",\n",
    "]\n",
    "X = features[feature_cols].values.astype(float)\n",
    "y = features[\"label\"].values.astype(int)\n",
    "X.shape, y.shape, y.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2a5e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "clf = XGBClassifier(n_estimators=300, max_depth=4, learning_rate=0.05,\n",
    "                    subsample=0.9, colsample_bytree=0.9, random_state=42,\n",
    "                    n_jobs=-1, tree_method=\"hist\")\n",
    "clf.fit(X, y)\n",
    "print(\"In-sample AUC:\", round(float(roc_auc_score(y, clf.predict_proba(X)[:,1])), 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad68040",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import Booster\n",
    "MODEL.mkdir(parents=True, exist_ok=True)\n",
    "booster = clf.get_booster()\n",
    "booster.save_model(MODEL/\"model.xgb.json\")\n",
    "meta = {\"feature_order\": [\n",
    "    \"income_inflow_30d\",\"spend_outflow_30d\",\"pct_gambling_spend_90d\",\"merchant_diversity_90d\",\n",
    "    \"avg_debit_amt_30d\",\"num_big_txn_30d\",\"days_since_last_salary\",\"debit_credit_ratio_90d\",\n",
    "    \"late_fee_count_90d\",\"debit_txn_count_30d\",\"credit_txn_count_30d\",\"net_cash_flow_30d\",\"cash_withdrawal_90d\",\n",
    "], \"version\": \"2.0.0-xgb\"}\n",
    "(MODEL/\"feature_order.json\").write_text(json.dumps(meta, indent=2))\n",
    "print(\"Saved artifacts to\", MODEL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc4d1c7",
   "metadata": {},
   "source": [
    "## Connect to hosted PostgreSQL and perform sanity check / scoring (set PGURL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1877dea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pandas as pd, psycopg2\n",
    "pgurl = os.environ.get(\"PGURL\"); assert pgurl, \"Set PGURL per data/DB_CONNECTIONS.md\"\n",
    "conn = psycopg2.connect(pgurl)\n",
    "print(\"Connected\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4067839a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: compute features for a few scoring customers and predict\n",
    "from xgboost import Booster, DMatrix\n",
    "sql = \"\"\"\n",
    "WITH expanded AS (\n",
    "  SELECT\n",
    "    t.customer_id,\n",
    "    t.snapshot_date AS S,\n",
    "    (e->>'ts')::timestamptz AT TIME ZONE 'UTC' AS ts,\n",
    "    (e->>'amount')::numeric AS amount,\n",
    "    (e->>'type') AS type,\n",
    "    (e->>'category') AS category,\n",
    "    (e->>'merchant') AS merchant,\n",
    "    (e->>'status') AS status\n",
    "  FROM bank_transactions_scoring t\n",
    "  CROSS JOIN LATERAL jsonb_array_elements(t.transactions) AS e\n",
    ")\n",
    "SELECT\n",
    "-- FILL in the query that will extract required features\n",
    "FROM expanded\n",
    "GROUP BY customer_id, S\n",
    "ORDER BY customer_id\n",
    "LIMIT 50;\n",
    "\"\"\"\n",
    "feats = pd.read_sql(sql, conn)\n",
    "meta = json.loads((MODEL/\"feature_order.json\").read_text())\n",
    "order = meta[\"feature_order\"]\n",
    "bst = Booster(); bst.load_model(MODEL/\"model.xgb.json\")\n",
    "dm = DMatrix(feats[order].values.astype(float), feature_names=order)\n",
    "probs = bst.predict(dm)\n",
    "out = feats[[\"customer_id\",\"snapshot_date\"]].copy()\n",
    "out[\"probability\"] = probs\n",
    "out[\"model_version\"] = meta.get(\"version\",\"unknown\")\n",
    "out.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c070ad",
   "metadata": {},
   "source": [
    "## ✅ Next steps (must-do deliverables)\n",
    "\n",
    "You now have a trained model in-memory. **You must persist model artefacts and complete deployment tasks.**\n",
    "\n",
    "### 1) Persist artefacts (required)\n",
    "- `model/model.xgb.json` — XGBoost booster (saved above)\n",
    "- `model/feature_order.json` — exact feature order the model expects\n",
    "\n",
    "> If these files do not exist yet, **re-run the “Save model artefacts” cell above**.\n",
    "\n",
    "### 2) Prepare for serving (required)\n",
    "- **Lambda script** (see `starter/lambda_handler.py`): loads the booster, accepts `{\"features\": {...}}`, returns probability.\n",
    "- **Docker image** using the provided `starter/Dockerfile` (Lambda base). Build & run locally.\n",
    "- **Invocation**: Call the container (or lambda-local) with features in the **exact** order from `feature_order.json`.\n",
    "\n",
    "### 3) Score hosted data (required)\n",
    "- Connect to the hosted PostgreSQL (see `data/DB_CONNECTIONS.md`).\n",
    "- Compute features from `bank_transactions_scoring` using the CTE in `feature_spec.md`.\n",
    "- Respect the feature order from `model/feature_order.json` and produce outputs:\n",
    "  - Columns: `customer_id`, `snapshot_date`, `probability`, `model_version`\n",
    "  - Format: CSV and/or JSON\n",
    "\n",
    "### 4) Submission (required)\n",
    "- The SQL used for feature computation\n",
    "- Trained artefacts: `model/model.xgb.json`, `model/feature_order.json`\n",
    "- Lambda/Docker code and a one-liner to run\n",
    "- A small README describing how you produced predictions\n",
    "\n",
    "> Tip: keep data access **read-only**; do not create server-side views/tables in the hosted DB.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609e9ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check: artefacts exist + hashes for reproducibility\n",
    "from pathlib import Path\n",
    "import hashlib, json, os\n",
    "\n",
    "MODEL = Path(\"model\")\n",
    "paths = [MODEL/\"model.xgb.json\", MODEL/\"feature_order.json\"]\n",
    "for p in paths:\n",
    "    assert p.exists(), f\"Missing artefact: {p}\"\n",
    "\n",
    "def sha256(path):\n",
    "    h = hashlib.sha256()\n",
    "    with open(path, \"rb\") as f:\n",
    "        for chunk in iter(lambda: f.read(8192), b\"\"):\n",
    "            h.update(chunk)\n",
    "    return h.hexdigest()\n",
    "\n",
    "print(\"OK — artefacts found:\")\n",
    "for p in paths:\n",
    "    print(f\"- {p}  size={os.path.getsize(p)}  sha256={sha256(p)}\")\n",
    "\n",
    "# Show feature order to reduce mismatches at serving time\n",
    "meta = json.load(open(MODEL/\"feature_order.json\"))\n",
    "print(\"Feature order:\", meta[\"feature_order\"])\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
